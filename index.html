---
layout: single
author_profile: true
---
<script type="text/javascript" src="assets/js/hidebib.js"></script>

<style>
    a {
        text-decoration: none;
        font-size:16px;
    }
    
</style>
<p style="font-size: 20px" ><b><center>Site in Progress</center></b></p>

<p style="font-size:16px;">
I am a Master's student at the <a href='https://www.ri.cmu.edu/'>Robotics Institute</a>, 
School of Computer Science, Carnegie Mellon University, 
working with <a href='https://en.wikipedia.org/wiki/Howie_Choset'>Howie Choset</a> and <a href='https://www.ri.cmu.edu/ri-faculty/matthew-j-travers/'> Matthew Travers</a>. 
I am  working on deep-learning to optimize autonomous exploration and navigation with limited perception in unknown dynamic/static environments.
<br>
<br>
My interests are in the research and development of intelligent systems and integrated robotics technologies to optimize and improve human life. 
Broadly in  machine learning, computer vision, planning and systems engineering particularly in perception, deep-learning and decision-making.
</p>
<div id="highlights"> 
<h2> Highlights </h2>
<ul style="font-size:16px">
    <li >May 2019 &nbsp Started <a href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-robotics/">Master of Science in Robotics</a></li>
    <li>May 2019 &nbsp Graduated accelerated 3-year B.S. in <a href="https://www.ece.cmu.edu/">ECE</a></li>
    <li>May 2019 &nbsp Co-led <a href="https://sites.google.com/view/cmu-jollyroger/home">JollyRoger</a> team to win 1st place award of $5,500 by <a href="https://www.leidos.com/">Leidos</a> in Mechatronic Design Capstone project: ShipBot, CMU</li>
    <li>Dec 2018 &nbsp Dean’s List CMU</li>
    <li>May-Aug 2018 &nbsp Worked at the intersection of perception and action in the Advanced Robotics Perception Team,<a href="https://www.amazonrobotics.com/#/">Amazon Robotics</a></li>
    <li>Apr 2018 &nbsp Won the <a href="https://www.cmu.edu/uro/MoM/2018-award-winners.html">Boeing Blue Skies Award: Game Changer</a> $1,000 for one of two presented research work in <a href="https://www.cmu.edu/uro/MoM/">Meeting of the Minds</a> Research Symposium </li>       
    <li>Jun 2017 &nbsp Awarded <a href='https://www.cmu.edu/uro/summer%20research%20fellowships/SURF/'>Summer Undergraduate Research Fellowship</a> $3500 CMU </li>       
    <li>May 2017 &nbsp Appointed as Motion Software Lead on CMU Research Team containing research staff in collaboration with Boeing.</li>
    <li>Sep 2016 &nbsp Started working in the <a href="http://biorobotics.ri.cmu.edu/">BioRobotics Lab</a></li>
    <li>Jun 2015 &nbsp Awarded <a href="http://online-inspire.gov.in/Account/INSPIREProgramme">INSPIRE</a> Internship, selected from top 1% rankers in their X Board Examinations by <a href="dst.gov.in">DST, Gov. of India</a></li>
    <li>Aug 2014 &nbsp Invited to be <a href="http://my.rsc.org/home">Chemnet</a> writer at <a href="https://www.rsc.org/">Royal Society of Chemistry UK</a> </li>
    <li>May 2014 &nbsp <a href="http://www.arkwright.org.uk/">Arkwright Engineering Scholarship</a> finalist</li>
    <li>2013 &nbsp Certificate of Merit Senior Kangaroo United Kingdom Mathematics Trust, UK</li>
    <li>2013 &nbsp Gold in Senior Maths Challenge United Kingdom Mathematics Trust, UK</li>
    <li>2013 &nbsp Gold in Intermediate Maths Challenge United Kingdom Mathematics Trust, UK</li>
   
</ul>
</div>

<div id="work"> 
<h2> Work </h2> 

<p style="font-size: 20px; margin: 0px"><b>Boeing Blaser Project | Carnegie Mellon University & Boeing Collaboration &nbsp; May 2019 – Present   </b></p>
<p style="font-size: 14px; margin: 0px; padding:0px">Graduate Research Assistant | Howie Choset </p>
<a href="javascript:toggleblock('bb_abs')" >abstract</a> | 
<a href="http://biorobotics.ri.cmu.edu/research/ConfinedSpacePerception.php" >webpage</a> | 
<a href="" >slides</a> 
<p align="justify"> <i id="bb_abs">
Designing VIO algorithms for running onboard an i.MX RT platform for developing a standalone miniature size, ultra-short range, and high accuracy laser-camera sensor module for applications in confined space. <br><br>
Developed a unified calibration procedure for simultaneous non-linear optimization on 9 parameters of camera intrinsics, laser-to-camera and hand-eye calibration.
Redesigned algorithm to speed up procedure run-time by 5x, over &lt30 images for 640x480 and 1280x960 camera resolutions. 
<br><br>
<b>Software</b>: C/C++, Python, Matlab, ROS<br>
<b>Hardware</b>: Blaser Sensor, UR5e<br>
<b>Key Concepts</b>: camera calibration, hand-eye calibration, camera-laser calibration, visual-inertial odometry, short-range high-precision perception
</i></p>

<p style="font-size: 20px; margin: 0px"><b>Boeing Sealant Application | Carnegie Mellon University & Boeing Collaboration &nbsp; May 2017 – May 2019   </b></p>
<p style="font-size: 14px; margin: 0px; padding:0px">Motion Software Lead | Howie Choset </p>
<a href="javascript:toggleblock('bs_abs')" >abstract</a> | 
<a href="http://biorobotics.ri.cmu.edu/research/ConfinedSpaceManipulator.php" >webpage</a> | 
<a href="" >slides</a> 
<p align="justify"> <i id="bs_abs">
Developed and implemented the closed-loop, high-precision motion control infrastructure and software with computer vision feedback for Boeing APADA Arm, automating sealant application and inspection on sub-millimeter cracks in aircraft wing bays. This solution reduces human error and improves worker health-safety as the sealant is noxious.<br><br>
Developed multiple trajectories for robot arm, based on permutations and combinations in shapes of cones and spirals to maximize scanning coverage area of the mounted sensor and nozzle of robot arm for sealant application. <br><br>
Implemented tracking and following of finger using short-range high-precision custom laser-camera sensor mounted on UR5e to demonstrate the high-precision closed loop control of the sensor and robot arm for confined space perception and manipulation. 
<br><br>
<b>Software</b>: C/C++, ROS<br>
<b>Hardware</b>: Custom 5DOF Arm, UR5e, Blaser sensor<br>
<b>Key Concepts</b>: kinematics, trajectory generation, motion planning, obstacle navigation, short-range computer vision
</i></p>

<p style="font-size: 20px; margin: 0px"><b>Amazon Robotics | Advanced Robotics Perception Team &nbsp; May – Aug 2018</b></p> 
<p style="font-size: 14px; margin: 0px">Advanced Robotics Intern | Chuck Llyod </p>
<!-- Text with Toggle -->
<a href="javascript:toggleblock('am_abs')" >abstract</a> |
<a href="" >media</a> 

<!-- Content to show after toggle -->
<p align="justify" style="font-size: 14px"> <i id="am_abs">
    Developed a computer vision based solution to the multifaceted issue of failed picks in the pick and place pipeline to stow away the items that come into the Amazon warehouse. I investigated and analyzed the existing pipeline to pinpoint the problem, incorrectly perceived 3D geometry caused by “holes” of missing data. This occured due to occlusion, reflectance, and the scanning angle of the static multi-sensor workspace rig.
    Thus my solution pipeline addressed this problem by: <br><br>
  
    • Identifying and locating the holes through angle criterion<br>
    • Validation of missing data versus physical hole<br>
    • Prioritizing filling order and executing re-planned picking path for scanning<br>
    <br>
    The solution implemented is based on the hybrid technique, as a pipeline using a sensor mounted on the end-effector of the robot to fill in data after detecting and confirming the existence of an area with missing data from image and point cloud space.<br><br>  
    Implemented the static sensors camera rig and environmental constraints of as-is implementation on the workstation; designed and 3D printed end-of-arm sensor mount. Demonstrated integrated modular pipeline on physical system.<br><br> 
    Also developed an alternate solution using classical techniques through PCL of surface reconstruction including triangulation, poisson reconstruction, voxel dilation etc; Pitched alternate solution for fitting shape primitives to approximate shape and used machine learning models to predict the geometry of the object.<br><br>
    
    <b>Software</b>: C/C++, ROS<br>
    <b>Hardware</b>: IntelRealsense D410, Ensenso, UR10<br>
    <b>Key Concepts</b>: sensor-fusion, motion planning, computer vision, point cloud to image reprojection
</i></p>



<p style="font-size: 20px; margin:0px"><b>FOXCONN IMR Fast-Vision | Carnegie Mellon University & FOXCONN &nbsp; May – Aug 2017
    </b></p> 
<p style="font-size: 14px; margin: 0px; padding:0px">Research Assistant</p>
<a href="javascript:toggleblock('fs_abs')" >abstract</a> |
<a href="assets/files/slides/" >slides</a> |
<a href="assets/images/" >media</a>

<p align="justify" style="font-size: 14px"> <i id="fs_abs">
Developed in-lab low-cost optical-flow sensor, containing two high fps cameras and an IMU, for high-speed localization of FOXCONN modular robots for multi-purpose use in dense industrial environment with serial communication 
and dynamic parameterization with ROS. Analyzed and selected apt off-the-shelf OEM barcode scanners, to develop this sensor
<br>
<b>Software</b>: Arduino, C/C++, ROS<br>
<b>Hardware</b>: IMU, Monocular Cameras<br>
<b>Key Concepts</b>: optical-flow, sensor-fusion, localization

</i></p>

<p style="font-size: 20px; margin: 0px"><b>Summer Undergraduate Research Fellowship &nbsp; May – Aug 2017</b></p>
<p style="font-size: 14px; margin: 0px; padding:0px">Research Assistant | Howie Choset & Guillaume Satoretti</p>
<a href="javascript:toggleblock('surf_abs')" >abstract</a>

<p align="justify"> <i id="surf_abs">
Awarded the Summer Undergraduate Research Fellowship 2017 for “Stable Stair Climbing for a Hexapod using Onboard Sensing” under Prof. Howie Choset and Dr. Guillaume. 
Researched and developed a gait, using Central Pattern Generators, for a hexapod robot in general terrain that is parameterizable by dimensions of obstacle extracted from camera feedback to make an ‘intuitive’ seamless 'walk to climb' transition increasing mobility, particularly for the introduction of legged companion robots in homes. <br>
Awarded the Boeing Blue Skies Award: GameChanger at the Meeting of the Minds Symposium 2018.
<br>
<b>Software</b>: Python, ROS<br>
<b>Hardware</b>: Hexapod, Kinect <br>
<b>Key Concepts</b>: cpgs, computer vision

</i></p>






</div>


<!-- Init hideblock for toggle -->

<script xml:space="preserve" language="JavaScript">
    hideblock('am_abs');
 </script>
<script xml:space="preserve" language="JavaScript">
        hideblock('fs_abs');
</script>
<script xml:space="preserve" language="JavaScript">
        hideblock('surf_abs');
</script>
<script xml:space="preserve" language="JavaScript">
        hideblock('bb_abs');
</script>
<script xml:space="preserve" language="JavaScript">
        hideblock('bs_abs');
</script>
<script xml:space="preserve" language="JavaScript">
        hideblock('surf_abs');
</script>
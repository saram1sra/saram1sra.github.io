---
layout: single
author_profile: true
---
<script type="text/javascript" src="assets/js/hidebib.js"></script>

<style>
    a {
        text-decoration: none;
    }
</style>
<p style="font-size: 20px" ><b><center>Site in Progress</center></b></p>

<p style="font-size:16px;">
I am a Master's student at the <a href='https://www.ri.cmu.edu/'>Robotics Institute</a>, 
School of Computer Science, Carnegie Mellon University, 
working with <a href='https://en.wikipedia.org/wiki/Howie_Choset'>Howie Choset</a> and <a href='https://www.ri.cmu.edu/ri-faculty/matthew-j-travers/'> Matthew Travers </a>. 
I am  working on deep-learning to optimize autonomous exploration and navigation with limited perception in unknown dynamic/static environments.
<br>
<br>
My interests are in the research and development of intelligent systems and integrated robotics technologies to optimize and improve human life. 
Broadly in  machine learning, computer vision, planning and systems engineering particularly in perception, deep-learning and decision-making.
</p>
<div id="highlights"> 
<h2> Highlights </h2>
<ul style="font-size:16px">
    <li >May 2019 &nbsp Started <a href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-robotics/">Master of Science in Robotics</a></li>
    <li>May 2019 &nbsp Graduated accelerated 3-year B.S. in <a href="https://www.ece.cmu.edu/">ECE</a></li>
    <li>May 2019 &nbsp Co-led <a href="https://sites.google.com/view/cmu-jollyroger/home">JollyRoger</a> team to win 1st place award of $5,500 by <a href="https://www.leidos.com/">Leidos</a> in Mechatronic Design Capstone project: ShipBot, CMU</li>
    <li>Dec 2018 &nbsp Dean’s List CMU</li>
    <li>May-Aug 2018 &nbsp Worked at the intersection of perception and action in the Advanced Robotics Perception Team,<a href="https://www.amazonrobotics.com/#/">Amazon Robotics</a></li>
    <li>Apr 2018 &nbsp Won the <a href="https://www.cmu.edu/uro/MoM/2018-award-winners.html">Boeing Blue Skies Award: Game Changer</a> $1,000 for one of two presented research work in <a href="https://www.cmu.edu/uro/MoM/">Meeting of the Minds</a> Research Symposium </li>       
    <li>Jun 2017 &nbsp Awarded <a href='https://www.cmu.edu/uro/summer%20research%20fellowships/SURF/'>Summer Undergraduate Research Fellowship</a> $3500 CMU </li>       
    <li>May 2017 &nbsp Appointed as Motion Software Lead on CMU Research Team containing research staff in collaboration with Boeing.</li>
    <li>Sep 2016 &nbsp Started working in the <a href="http://biorobotics.ri.cmu.edu/">BioRobotics Lab</a></li>
    <li>Jun 2015 &nbsp Awarded <a href="http://online-inspire.gov.in/Account/INSPIREProgramme">INSPIRE</a> Internship, selected from top 1% rankers in their X Board Examinations by <a href="dst.gov.in">DST, Gov. of India</a></li>
    <li>Aug 2014 &nbsp Invited to be <a href="http://my.rsc.org/home">Chemnet</a> writer at <a href="https://www.rsc.org/">Royal Society of Chemistry UK</a> </li>
    <li>May 2014 &nbsp <a href="http://www.arkwright.org.uk/">Arkwright Engineering Scholarship</a> finalist</li>
    <li>2013 &nbsp Certificate of Merit Senior Kangaroo United Kingdom Mathematics Trust, UK</li>
    <li>2013 &nbsp Gold in Senior Maths Challenge United Kingdom Mathematics Trust, UK</li>
    <li>2013 &nbsp Gold in Intermediate Maths Challenge United Kingdom Mathematics Trust, UK</li>
   
</ul>
</div>

<div id="work"> 
<h2> Work </h2> 
<p style="font-size:16px">

<h4>Amazon Robotics</h4> 
Advanced Robotics Perception Team | Advanced Robotics Intern 
<br>
<!-- Text with Toggle -->
<a href="javascript:toggleblock('am_abs')" >abstract</a> 

<!-- Content to show after toggle -->
<p align="justify"> <i id="am_abs">
    I developed a computer vision based solution to the multifaceted issue of failed picks in the pick and place pipeline to stow away the items that come into the Amazon warehouse. I investigated and analyzed the existing pipeline to pinpoint the problem, incorrectly perceived 3D geometry caused by “holes” of missing data. This occured due to occlusion, reflectance, and the scanning angle of the static multi-sensor workspace rig.
    Thus my solution pipeline addressed this problem by: 
  
    <li>Identifying and locating the holes through angle criterion</li>
    <li>Validation of missing data versus physical hole</li>
    <li>Prioritizing filling order and executing re-planned picking path for scanning</li>
    <br>
    The solution implemented is based on the hybrid technique, as a pipeline using a sensor mounted on the end-effector of the robot to fill in data after detecting and confirming the existence of an area with missing data from image and point cloud space.<br><br>  
    Implemented the static sensors camera rig and environmental constraints of as-is implementation on the workstation; designed and 3D printed end-of-arm sensor mount. Demonstrated integrated modular pipeline on physical system.<br><br> 
    Also developed an alternate solution using classical techniques through PCL of surface reconstruction including triangulation, poisson reconstruction, voxel dilation etc; Pitched alternate solution for fitting shape primitives to approximate shape and used machine learning models to predict the geometry of the object.<br><br>
    Software: C/C++, ROS<br>
    Hardware: IntelRealsense D410, Ensenso, UR10<br>
    Key Concepts: Sensor Fusion, Motion Planning, Computer Vision, Point Cloud to image reprojection
</i></p>







</p>
</div>


<!-- Init hideblock for toggle -->

<script xml:space="preserve" language="JavaScript">
    hideblock('am_abs');
 </script>